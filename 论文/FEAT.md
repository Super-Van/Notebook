# Few-Shot Learning via Embedding Adaptation with Set-to-Set Functions

## Abstract

使用有限的数据进行学习是视觉识别的一个关键挑战。许多少小样本学习方法通过从已见过的类中学习实例嵌入函数（instance embedding function）并将该函数应用于带有限标签的未见过类的实例来解决这一难题。这种类型的==迁移学习是任务不可知型（task-agnostic）的==：嵌入函数并不是区分未见过类的最佳学习方法，辨别这些类就产生了目标任务。在本文中，我们提出了一种新的方法，==通过一个集合到集合的函数（set-to-set function）使得实例的嵌入（instance embedding）适应目标分类任务，此方法产生专注于特定任务（task-specific）且区分度高的嵌入==。我们实证研究了这种集合到集合函数的各种具体实现（instantiation），并观察到Transformer是最有效的——因为它天然满足我们所需模型的关键属性。我们将该模型表示为FEAT（借助transformer的小样本嵌入适应），并在标准小样本分类基准数据集和四个扩展的小样本学习设置（即跨域、传导（transductive）、广义小样本学习（generalized few-shot learning）和加压（low-data learning））上作了验证。它对基线模型和以前的方法进行了一致的改进，并在两个基准集上建立了最优的结果。

## 1. Introduction

在解决学习注释非常有限的新视觉概念的挑战上，小样本视觉识别[10,23,24,27,49]成为一个有前景的方向。具体地说，它区分了两组视觉概念：已见过的视觉概念和未见过的视觉概念。目标任务是构造视觉分类器，识别没见过的类别，其中每个类别都有非常少的实例（“few-shot”）。主要思想是在已见过的类（这些类具有足量的标记实例）中发现可迁移的视觉知识，然后利用这些知识来构造所需的分类器。例如，==目前最优的小样本学习方法通常在已见过类别上学习鉴别性实例嵌入模型（discriminative instance embedding model），并将其应用于未见类别中的视觉数据。然后在这个共同的嵌入空间（embedding space）中，使用非参数化（参数皆不更新）的分类器（如nearest Neighbors）==来避免从少量实例中学习复杂的识别模型。

这种方法存在一个重要的局限性。假设一个共同的嵌入空间意味着在已见类上发现的知识——鉴别性视觉特征（discriminative visual features，特征之间差异比较大，当然差异越大越好辨别）——对于任意一组随机从未见类构造出来的分类任务都同样有效。具体来说，假设我们有两个不同的目标任务：辨别“猫”和“狗”以及辨别“猫”和“老虎”。直观地说，每个任务都使用一组不同的鉴别性特征。因此，最理想的嵌入模型首先需要能够同时为任一任务提取有区分度的特征（discerning features）。这本身可能是一个具有挑战性的方面，因为当前的方法不知道那些“下游”（后续、下一阶段）目标任务是什么，并且可能会无意中弱化（de-emphasize）特征的选择，这些特征又供将来使用。其次，即使提取了这两组鉴别性特征，它们也不一定能为特定的目标任务带来最佳的性能。辨别“猫”与“虎”的最有用的特征可能与辨别“猫”与“狗”的任务无关，甚至也可能是噪音！

当前的几种所有表学习方法缺少的是一种适应策略，该策略将从已见过类中提取的视觉知识裁剪（tailor，或缝补？）为目标任务中未见类的视觉知识。换句话说，我们需要孤立分离的嵌入空间，其中每一个都是定制（customized）的，这样视觉特征对于给定的任务来说是最有区分度的。为此，我们提出了一种基于小样本模型的嵌入自适应方法（embedding adaptation method），用于调整（adjust）从已见类生成的（derived）实例嵌入模型。这种基于模型的嵌入自适应需要一个集合到集合的函数：一个函数映射，它从小样本support set中获取所有实例，并输出一组已经过自适应过程的support实例的嵌入，这组元素彼此协同自适应（co-adapting）。然后将这些输出嵌入组装（assemble，聚集？）为各个视觉类别的原型（prototype），并为最近邻分类器做准备。图1定性描述了嵌入适应过程（作为我们最佳模型的结果）。这些类原型在嵌入空间中朝着每个类别的样本簇发散，表明嵌入适应的有效性。

在本文中，我们使用各种函数逼近器（function approximators）实现集合到集合的转换，包括双向LSTM[16]（Bi LSTM）、深度集合（deep sets）[56]、图卷积网络（graph convelutional network，GCN）[21]和Transformer[29,47]。我们的实验结果（参考§5.2.1）表明，==Transformer是最有效的参数选择，同时最好地实现了所需的集对集转换（set-to-set transformation）的关键属性，包括上下文化（contextualization）、排序不变性（permutation invariance，或叫次序无关性，如何证明呢？）、内推（interpolation）和外推（extrapolation）能力（见4.1）。==因此，我们选择使用带Transformer的实例化的集到集函数作为最终模型，并将其表示为FEAT（Few-shot Embedding Adaptation with Transformer）。我们进一步对FEAT进行综合分析，并在许多扩展任务上对其进行评估，包括小样本域泛化、转导小样本学习和广义小样本学习。我们的总体贡献在三个方面：

- 我们通过使用集合到集合的转换，将小样本镜头学习形式化（formulate）为基于模型的嵌入自适应，以制造出针对特定任务的实例嵌入。
- 我们用各种函数逼近器实例化了这种集合到集合的转换，验证并分析了它们的小样本学习能力、任务插值能力和外推能力等。它总结出了我们的模型（FEAT），该模型使用transformer作为集合到集合的函数。
- 我们在各种扩展的小样本学习任务上评估了我们的FEAT模型，与强基线方法相比，它实现了优异的性能。

## 2. Related Work

专门为小样本学习设计的方法大致分为两类。第一个是控制如何为目标任务构造出一个分类器。一个富有成效的想法是元学习框架，在该框架中对分类器进行了优化，以预期未来基于新任务中的数据的更新在该任务中表现良好[2,3,10,13,26,32,36,40]，或者分类器本身直接由新任务数据进行元预测（meta-predict）[35,53]。另一种方法侧重于学习可泛化的（generalizable）实例嵌入[1,5,6,17,22,31,42,46,49]，并将这些嵌入用于简单分类器，如最近邻（NN，nearest neighbor）规则。关键的假设是嵌入捕获了数据的所有必要的鉴别性表示（discriminative representations），这样一来简单的分类器就足够用（suffice）了，从而避免了在少量标记实例上过拟合的危险。早期的工作，如[22]首先验证了嵌入在one-shot学习中的重要性，而[49]则建议按照元学习例程，使用soft NN目标学习嵌入。最近的进展利用了不同的目标函数来学习这些嵌入模型，例如。考虑类原型[43]、决策排名（decision ranking）[46]和相似性比较（similarity comparison）[45]。最近，[41]利用图卷积网络（GCN）[21]来统一嵌入学习。

我们的工作遵循第二学派的思想。但主要区别在于，我们==不认为在已见类上学习的嵌入对目标任务是不可知的，因此对于这些任务来说，它们必然是有区分度（discriminative）的。相比之下，我们提出使用集到集的函数为每个具体目标任务调整（adapt）这些嵌入，以便转换后的（transformed）嵌入更好地与这些任务中所需的区分度（discrimination）保持一致==。我们的经验表明，这种任务特定型的嵌入比任务不可知型的嵌入性能更好。MetaOptNet[25]和CTM[28]也遵循学习任务特定型嵌入（或分类器）的精神，具体做法是优化（optimization）目标任务或使用聚焦（concentrator）和投影（projector）使距离度量（distance metric）专注于特定任务。

## 3. Learning Embedding for Task-agnostic FSL

见手写笔记

## 4. Adapting to Task-Specific Embeddings

在下文中，我们将介绍我们的小样本学习（FSL）方法。我们首先描述主要思想（§4.1，也如图2所示），然后介绍集到集的适应（调整）函数（§4.2）。最后是（模型的）学习（§4.3）和实施细节（§4.4）。

### 4.1 Adapting to Task-Specific Embeddings

我们的方法与传统方法的关键区别在于==学习对特定任务的嵌入==。我们认为嵌入函数并不理想。特别是，==对一个特定任务来说嵌入不一定强调出最具有鉴别性的表示（representation）。为此，我们引入了一个自适应步骤（调整步骤），其中嵌入函数（更准确地说，它在实例上的值）被转换。这种转换是一个集到集函数，它对某集合的图像实例上下文化，以实现每个项（实例）的强协同适应（互相适应，co-adaptation）==。实例函数不具有这种强协同适应属性。此外，集到集函数接收实例作为一个整体（bags），或无序的集合，==要求函数在排序无关的条件下输出提纯的（refined）实例嵌入的集合==。具体而言，公式。

### 4.2 Embedding Adaptation via Set-to-set Functions

接下来，我们将对充当集到集嵌入适应函数实例化的各种选择作出解释。

双向LSTM（BILSTM bidirectional LSTM）[16,49]是实例化集到集转换的常见选择之一，其中每个BILSTM单元（cell）的输入和隐藏层输出之间的相加产生了适应了的嵌入。值得注意的是，BILST的输出应该是取决于输入集的顺序。请注意，使用双向LSTM嵌入适应模型与完全条件嵌入（fully conditional embedding）[49]类似，但又有不同，后者将训练实例嵌入和测试实例嵌入一起上下文化，从而产生一种转导设置。

……

**Transformer** 最终我们使用Transformer架构[47]来实现T函数。特别是，我们采用自注意（self-attention）机制[29,47]来转换每个嵌入实例，考虑其上下文（contentual）实例。请注意，它天然地满足T函数所需的属性，因为它输出提纯了的实例嵌入，并且是无关实例次序的。

### 4.3  Contrastive Learning of Set-to-Set Functions

为了促进嵌入适应的学习，我们在通常目标的基础上==增加了一个对比目标（contrastive objective）。它旨在确保自适应后的实例嵌入与同类的邻居更加相似，与不同类的邻居更加不相似（缩小类内间距，扩大类间间距）==。具体来说，嵌入适应函数应用于整个episode每个实例，它产生了已经transformed的query（test）的嵌入和类中心cn。然后，我们应用对比目标，确保相比其他中心，训练实例更接近其自己的类中心。总目标函数（连同式1）如下所示：

这种对比学习使得set transformer能够==提取同一类别实例的公共特性（characteristic），从而保持各个类别（category-wise）的（内部）相似性（similarity）==。

### 4.4 Implementation details

我们考虑了三种不同类型的卷积网络作为嵌入函数的主干：1）4层卷积网络（ConvNet）[43.46.49]，2）12层残差网络（ResNet）在[25]用了，3）宽残差网络（WideResNet [40].[55]）。我们为这些主干应用额外的基于已见过类的预训练阶段，在此基础上进一步优化我们重新实现的方法。为了实现更精确的嵌入，我们在使用集到集transformation进行嵌入适应之前，对训练集中相同的类实例求平均。Adam[20]和SGD分别用于优化ConvNet和ResNet变体。此外，我们遵循这四个集到集函数——BiLSTM[16]、DeepSets[56]、图卷积网络（GCN）[21]和Transformer（FEAT）[47]的最标准实现。我们建议读者参考补充材料（SM），以了解每个集到集函数的完整细节和消融研究。
