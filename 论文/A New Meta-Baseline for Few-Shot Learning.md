## A New Meta-Baseline for Few-Shot Learning

这次想介绍的论文是《A New Meta-Baseline for Few-Shot Learning》，其中的关键词是叫meta-baseline，一般翻译为元基线，是元学习meta-learning的一个方法。这个方法是作者在2020年提出的。

#### 前情回顾

这个few-shot learning小样本学习在上一次汇报中我已经介绍了一下，简而言之就根据少量参考图片，来预测一张图的类别。那么我理解的它的出发点或目标无非是两个：一个是希望样本尽可能少，因为大量样本需要高成本和更长的学习时间；二是能对从没见过的新类别作分类。后面我们就看看作者的方法和实验对这两点目标的实得怎么样。

#### 方法介绍

作者主要提出了两种方法：classifier-baseline和meta-baseline，后者是前者的改良版。值得注意的是它们是方法或流程而不是一个拥有某种结构的模型，而且它们使用完全相同的模型结构，后面我们会见识到。

我们先看看classifier-baseline是个什么样的东西，它一般译作分类器基线。来看看它的流程，我们给一个训练集，取其中一张图像为代表，将它输进一个分类器，其实就是一个网络结构，也可以叫做编码器encoder或主干网络backbone。以我运行的代码里的那个残差网络ResNet-12为例，经过这个分类器里最后一层卷积之后它吐出一个维度为512\*5\*5的feature map，512是通道数，两个5就是宽和高。然后我们把后面两个维度降下来，把25个值拉平，就得到一个512*25的张量。接着对25这个维度求均值，其实就是对feature map求均值，得到一个512\*1的向量，这个向量就是分类器提取出来的特征向量。然后再把它输进全连接层又吐出一个向量。它的维数与分类标签数是一致的，比如我跑的代码里整个训练集是共有64个类别，那它就是一个64维的向量。让它流经softmax分类器，就得到一个标量，表示64个概率值里面最大的那个。最后我们将其与实际标签联合起来做交叉熵损失，然后反向传播，更新分类器的参数。于是我们发现这一部分其实就是监督学习。监督学习目的是什么呢？就是要得到一个作图像特征提取的分类器，就是这里的f$\theta$。我们会使用这个分类器来做下一步-给定support set，完成小样本分类任务。

我们先看看一个few-shot task大体上是什么样的。这里面的关键词就是上次提到的N-way、K-shot再加一个Q。一个few-shot task应当有一个数据集，其中又分为两部分-support set-参考图片的集合和query set-待预测图片的集合。我么看这排布得很清楚，一共有N个类别，竖着看的话，每个类别下有K个参考样本和Q个查询样本或叫预测样本，加起来一共要从源数据集采集这么多样本。我们要做的呢就是根据support set，预测query set中某一个样本的类别。预测方法就有很多了，比如上次谈到的连体网络。但作者提出了一个既简单有高效的方法，我们看看是什么样的：

我们把监督学习得到的分类器拿过来，将support set中的全体图像数据输进去，比如这里有3个类，每个类包含两个参考样本，那么就得到3组-6个特征向量。然后我们对每一组求平均值，这个平均值好理解吧，比如求这个5个行向量的平均值，我们就按列作计算，简单地得到结果。最好呢对均值向量再做个单位化，就是把原向量映射成一个模为1的单位向量，至于为什么这么做稍后大家就会明白。接下来把某一张query图输进分类器，得到它的特征向量，也对它作单位化。最后把对它和这左边三个做一个余弦相似度的计算，它会吐出一个预测值，指代预测的类别，具体可能是0或1或2。最后这一坨呢作者也把它叫做余弦最近质心方法。

简单理解一下这个方法。这儿有两个单位向量，当θ角为0的时候，它们就重合了或者叫同方向，我们就把它俩想象成两个特征向量，两个特征向量的夹角θ越小意味着它们的相似度越高，也意味着它们很可能属于同一个类别。进而我们就想如何度量夹角θ呢？可以借助余弦函数。这里有个简单的数学推导，cosθ取最大值1和θ取2kπ是等价的，也就是说cosθ越趋近于1，θ角就越趋近于0。再看由两个向量的内积公式可以得到cosθ=它们的内积除以它们的模的积，而如果它们的模都是1的话，这个余弦值就恰好=内积了。

好，我们回头看看这几个提取出来的特征向量，前三个是各个类别的平均特征向量，分别用μ1、μ2、μ3表示，用q表示query图的特征向量。它们的维度当然都很高了，便于理解，我们就当它们都是二维的，把它们映射到特征空间中，假如得到这么一个结果。不难看出，角θ1最小，即q和μ1的方向最接近，即query图的类别很可能是第一类。

下面我们看看具体是怎么算出来的。令大M矩阵由三个类的特征向量拼起来，那么M乘q就得到一个3维的相似度向量，便于理解，把维度都标上。这个512用的是刚才提到的跑的代码里的那个残差网络的输出维度。我们看第一个元素是μ1的转置乘以q；第二个元素是μ2的转置乘以q；以此类推。然后对它作softmax分类，得到一个概率分布的p向量，它里面最大值的下标就是我们最终要得到的预测类别。我们还可以推广，将一张query图的特征向量变成query set的特征向量集合，就成一个矩阵了，作者取的大Q是15，所以3\*15，这里一共有45个向量。它俩乘起来得到相似度矩阵。我们看第一列是由M乘以q1得到的；第二列是由M乘以q2得到的；以此类推。

于是我们可以把这个query换成query set，连同support set一起整个扔进分类器，这样一来运算效率会大大提高。

以上就是分类器基线classifier-baseline的完整流程。

下面看它的进阶版-meta-baseline，一般译作元基线。由两个阶段组成：预训练阶段和元学习阶段。

这个预训练阶段其实就是刚才classifier-baseline的训练阶段，就是监督学习的过程。这个过程旨在获得一个分类器或者encoder，用来做特征提取和实现基类到新类的迁移泛化，就是说即使support set中的类别都是从未见过的，模型也能很好地判别。

元学习阶段也可理解为二次训练阶段或者叫基于小样本学习的训练，这是相对于预训练是基于监督学习来说的。我们看向量p是服从概率分布的，之前我们说只获取最大概率值的下标，现在就要将最大概率值也一起取出来。干什么呢？我们可以把这里的logit抹掉，替换成argmax(p)，它们同一个值，然后这里的cosine similarity还能吐出这个max(p)，对吧？让它连同query的真实标签作交叉熵，接着反向传播，更新分类器参数。所以大家能看出来这就叫预训练之后的二次训练，而且是基于小样本的学习的训练。

以上就是作者所提出的两个方法的过程。

#### 实验过程

下面看看作者的实验。由于作者做了大量的对照试验，但我自己呢时间有限、资源有限，所以我就根据跑出来的代码，代表性地介绍一段比较完整的实验。

先看下数据集miniImageNet，它是小样本学习的行业标准数据集。它一共有100个类别，每个类别包含600张图像。它被划分为三块，作者只用了两块，上面这一块的64个类别在实验中可以称作基类，下面这块20个类可以称作新类。作者从上面这块中分两次取了两拨数据，一拨是全体数据38400张-64乘600，另一拨是随机选取的18748张。从下面这块中又取了一拨数据，随机抽取12000张。至于它们分别干什么用的，我们稍后会弄清楚。作者手动把它们封装成几个数据源文件，就不是拿原始的miniImageNet数据集来用了。

train classifier是个文件名，来看看这个文件执行起来是什么样的。总共跑100轮，在每一轮，先进行训练，这是它的背景：监督学习，基类的所有图片全部用上，batchsize是128，每轮有300次迭代，基于一次迭代或一个batch作反向传播，并累加上当前batch的损失和正确率，然后自动地计算平均值。接着是验证，同样是监督学习，batchsize也是128，不过用的是取自基类的另一拨数据，每轮有145次迭代，没有反向传播，累加损失和正确率求平均值。最后是当epoch是5的倍数时，才进行小样本验证，其实这里有两次小样本验证，第一次完了再做第二次，我把它们合起来了。一次是1-shot，一次是5-shot。两次都是5-way，都有200个batch，每个batch有4个任务，每一个任务所用到的数据是从新类的12000张图中采样得到的。像这里，它们的Q都是15，都有75个query。而一个1-shot任务需采样80张图，一个5-shot任务需采样100张图，每个任务间的图像是可以重复的。那么算上batchsize和batch总数的话前面还都乘上200和4。

回顾刚才介绍的元基线的流程，这里的训练其实就是预训练，前提是后面会有二次训练。100轮结束之后，会生成一个epoch-last文件，保存最后一轮训练的分类器状态信息，准备提供给元学习阶段使用。根据每一轮验证的正确率还会生成一个max-va文件，保存验证正确率最高的那一轮的分类器参数备用。

然后train meta也是一个文件名，来看看执行它会是什么样。它总共跑20轮，在每一轮，也是分三段-训练、训练验证和小样本验证。那么这些背景我就不详细说明了。这三段做的都是小样本任务。可以想到如果训练用到了预训练出的分类器，也就是加载epoch-last文件，那么这里的训练连同预训练就构成了meta-baseline方法；而如果不用epoch-last文件，直接随机地取分类器的参数，那么可以把这段训练叫做meta-learning from scratch。第二段训练-验证是用来和训练作对比的，对比的是正确率，以此来探讨随着训练的深入，元基线在基类和新类上的性能变化。最后一段小样本验证是用来得到最佳的元基线方法，也就是最优的分类器参数。

我们简单回顾一下这两个文件的执行过程。执行train classifier就相当于分类器基线方法，执行train meta不使用预训练好的分类器呢就相当于从零开始的元学习，使用的话呢就相当于元基线。我们看这几个不同的方法或过程有着模型结构和主干网络结构，不同的只是状态或者参数，本质上还是主干网络的参数。不同的方法得到不同参数，也就得到特征提取能力有差异的分类器，最终决定模型的分类性能有有高有低。

所以我们就来测试一下它们到底谁高谁低，谁最牛逼。测试还是小样本分类任务，是在新类上进行的。最后我们只关注正确率。

那么这就是作者给出的结果，不同的网络，不同的数据集，元基线总是表现得最好。另外作者还指出：在主干网络越深和数据集越大的条件下，黄柱子跟红柱子的差距就越大，也就意味着预训练的作用越强。

#### 结果分析

再往下看一些其他结果。

按照行业标准，作者在miniImageNet和tieredImageNet这两个数据集上进行了实验，并和前人的工作进行了比较，展现在下面这两张表上。那么能观察到尽管设计简单，但元基线meta-baseline的性能大大优于之前的那些比较好的元学习方法。我们还注意到，与以前的方法相比，更简单的分类器基线classifier-baseline的竞争力也不错，尤其是在5-shot任务中。

随后，作者在大规模数据集ImageNet-800上进一步评估了自己的方法。观察到在这个大的数据集中，元基线改进了分类器基线。

我们刚刚谈到，随着元学习或二次训练的推进，模型在基类和新类上的表现会有不同吗？作者用实验给出了答案：从这张图上我们清楚地看出，不论基于哪个数据集，随着轮数增加，基类上的分类正确率在上升，但新类上的正确率在下降。作者首相想到的原因可能是过拟合，实质上就是数据集太小，于是他就在更大规模的数据集ImageNet-800上实验，却发现这个问题依然没有缓解。最后作者给出的解释是元学习阶段存在着客观差异，意思就是基类数据集和新类数据集之间毫无交集的差异，这种问题其实在以前的监督学习中也是很普遍的。

下面讨论一下预训练的重要性。作者的假设是预训练的分类器为元学习阶段提供了从基类到新类的迁移能力，为了证实这一假设，作者比较了没有经过预训练的元学习方法和有预训练的元基线方法的性能。从这张表可以看出，虽然这个from scratch就是从零开始的元学习在基类上的性能略高一筹，但是在新类上的性能就和元基线差很多，这就体现了预训练的泛化作用。

然后作者讨论了分类度量的重要性。就是在分类器基线中拥有一个好的分类预测方法也是很重要的。前人在原型网络prototypical networks中提出使用平方欧氏距离作为度量方法，于是在预训练过程完全一致的条件下，作者使用它代替余弦距离做对比实验，结果见这张表。不难看出对meta-baseline来说，余弦距离是更好的选择。

最后作者讨论了元学习的使用条件，就不是说元学习或二次训练在任何情况下都是必要的。作者考虑了几个因素，简单归纳一下：第一个因素是类之间的相似性，作者观察到如果新类与基类足够相似，那么随着基类训练的进行，新类的泛化能力或分类正确率也应该不断提高。其次是数据集的规模，当数据集的规模变大时，元学习的改进就不明显了，主要原因是在更大的数据集上预训练出的分类器的迁移能力更强，因为毕竟类别更多，那么元学习的改进能力相对地就变弱了。第三个因素是shot值，作者观察到元学习阶段针对5-shot的改善远小于1-shot的改善，作者假设是shot越大，由该类提取出的平均特征就越好，因此元学习的改进也相对变弱。最后是主干网络的尺寸，作者注意到网络很浅的话，分类器基线的性能就优于元基线，意味着元学习更适合更深的网络结构。

最后附上一段作者所归纳的论文贡献，大家可以快速地看一下，这几点刚才差不多都介绍了。

#### 代码运行

由于时间和资源的问题，我改了一些参数，跑出来的效果没有作者的那么好。

这是预训练的打印结果，训练的平均损失和平均正确率……。最终分类器基线的性能达到百分之……，由于轮数很少，所以跟作者的有差距。

这是元学习后的打印结果，也是因为轮数不够多，所以看不出在基类和新类上的性能一个升一个降，这里是都在上升。

这是元基线的测试结果，轮数我也降了下来，没有作者的结果好。

另外，还有一些tensorboard可视化的损失和正确率的变化图，我没能从服务器上扒下来，所以就没贴。

在代码的整个一套运行流程中可以修改很多配置，来作对照试验，节省时间我就只做了最简单的一套，就是刚刚贴出来的这些。

完了，谢谢大家。