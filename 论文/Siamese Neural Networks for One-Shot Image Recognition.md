## Siamese Neural Networks for One-Shot Image Recognition

机器学习应用中学习好的特征的过程需要极高的计算代价，并且在数据很少的情况下可能会很困难。这方面的一个典型例子是one-shot学习，其中每个类别只给定一个样本，但我们必须正确地预测。

在本文中，我们探索了一种学习==孪生神经网络==的方法，==它采用一种独特的结构自发地对各输入的相似度进行排名。网络一旦优化好了，我们就可以利用其强大的辨别（看出两张图描绘的不是同一种东西）能力，将网络的预测能力不仅泛化到新数据，而且泛化到来自未知分布的新类别==。使用卷积架构，我们能够在one-shot分类任务上获得绝佳结果，超越其他深度学习模型，并获得一流的性能。

总结：泛化能力强；性能也高。

#### 引入

##### 概述

第一段关于人的研究省略。

机器学习已经成功地用于在各种应用中实现最先进的性能，例如网络搜索、垃圾邮件检测、字幕生成以及语音和图像识别。然而，==当被迫对几乎没有监督信息（没有人为指定标记）的数据进行预测时，这些算法往往会崩溃。我们希望将其泛化到这些陌生的类别，而无需额外的再训练==，这可能是昂贵的或不可能的，因为受限于有限数据或在线预测的背景设定（如网络检索）。

一个特别有趣的任务是在某种限定条件下作分类，该条件即：在对待测实例进行预测之前，我们可能只能观察每个可能类别的一个样本。这就是所谓的one-shot learning，即我们在这项工作中所提出模型的主要焦点。它应该与zero-shot learning相区别，关于后者，模型看不到目标类别的任何样本。

下一段关于孩子的讲述省略。

one-shot学习的问题可以通过开发特定领域的特征或推理过程来直接解决，这些特征或推理过程对目标任务（特定任务）具有高度的区分能力。因此，采用这些方法的系统往往在实例相似的情况下（特定领域）表现出色，但鲁棒性差，不适用于其他类型的任务。在本文中，我们提出一种新的方法，即限制对输入结构的假设，同时自动获取特征，使模型能够从小样本中成功推广。我们建立在深度学习框架的基础上，该框架使用许多非线性层来捕捉输入空间中变换的共性，通常是通过==利用具有许多参数的模型==，然后==使用大量数据来防止过拟合==。这些功能非常强大，因为我们能够在不施加强先验的情况下学习它们，尽管学习算法本身的成本可能相当高。

##### 相关工作

省略。

##### 方法

我们看中的是字符识别（character recognition）。我们采用大型孪生卷积神经网络，它的特点有：

- 能够==学习普适性强的图像特征（准确判断两图像相不相似，前提是要提取好特征）==，用于预测前所未见的类分布，即使这些新类别的可用样本很少。
- 易于使用标准优化（optimization）技术对从源数据（大训练集）中采样的样本对进行训练。
- 通过利用深度学习技术，提供不局限于特定领域知识的竞争方法。

为了开发一个用于one-shot（小样本）图像分类的模型，我们的==目标是首先学习一个能够确定图像对的相似性的神经网络，这是图像识别的标准验证（verification，或叫匹配、比对）任务==。也就是说，给定来自相同字母表的任意两个图像，该网络将预测它俩是否描绘相同的字符。

我们假设擅长验证的网络可以推广到one-shot分类。==匹配模型根据输入对属于同一类或不同类的概率来识别输入对。然后，该模型以成对的方式对照单独的测试图像来评估新图像。然后，基于匹配网络得分最高的配对被赋予分类任务的最高概率。==如果匹配模型学习到的特征足以肯定或否认一组手写字母表中的字符的同一性，那么它们应该足以应付其他字母表，==只要该模型已接触过各类字母，锻炼了到特征之间的差异、变化==。

总的来说，首先通过基于监督度量的孪生神经网络学习好的表示（特征提取），然后==在没有任何再训练的情况下复用该网络的特征进行one-shot学习==。

####  Omniglot 数据集

##### 概述

本数据集有1623种字符，它们来自50个字母表，每个字母表的字符数从15到40个不等。每种字符由20个书写者写一遍，共32460个样本。数据集又分为背景集（background set）和评估集（evaluation set）：

- 背景集取自40个字母表，包含964种类别，19280个样本。
- 评估集取自10个字母表，包含659个类别，13180个样本。

背景集用于通过学习超参数和特征映射（feature mapping）来开发（优化）模型，而评估集仅用于衡量one-shot分类的性能（时间、准确率等）。

##### one-shot 学习任务

为了评估one-soht学习的性能，Lake设计了一个20个字母的分类任务，首先从评估集中选择一个字母表，再从字母表里随机抽取20种字符，再从20个书写中随机选2位（A和B）来分别写这20个字符。A写的20个作为待测图片，每一个都拿来同B写的20个一一比对。就按照这个过程，对评估集的每一个字母表重复两次，故一共得到400（10\*2\*20）次预测实验，基于此计算分类准确率。

#### 用孪生神经网络作图像==匹配==

##### 概述

孪生神经网络由两个网络组成，这两个网络接受不同的输入，但在顶部由一个能量函数连接。该函数计算两侧最高层特征表示之间的某种度量。两个网络之间的参数是一模一样的。该策略有两个关键属性：

- 它确保其预测的一致性。权重捆绑保证了两幅极其相似的图像不可能被它们各自的网络映射到特征空间中相去甚远的位置。
- 网络是对称的：如果我们向孪生网络给定两个不同的图像，顶部结合层将计算相同的度量，就像我们向相反的双胞胎呈现相同的两个图像一样。

以上内容不好说，还不如看图来得直观明了。

在本文中，我们使用双特征向量h1和h2之间的加权L1距离结合sigmoid激活，将其映射到区间[0, 1]。因此，交叉熵目标自然而然成了训练网络的最佳选择。

##### 模型定义

翻译就不贴了，之后直接上图。

##### 学习

损失函数、优化器、权重和偏置的初始化、学习率和动量的设置之后结合代码再谈。

我们对每个网络进行了最多300轮的训练，每轮训练完后都会在320个one-shot学习任务中监控了one shot validation error，这些任务是从==验证集==中的字母表和书写者中随机生成的。当验证误差连续20轮没下降，我们就停止训练并根据最小误差取得==最佳模型参数==。如果验证误差在整个学习过程中一直在下降，我们就保存模型的最终状态。

仿射扭曲。具体做法无需深究，只知道相当于给图形作分身、变形就行了。

##### 实验结果

为了==训练匹配网络==，我们分别用30000、90000和150000个训练样本生成了三个不同大小的数据集（训练集）。我们将总体数据的60%用于训练：即从50个字母表中取30个（30000/30/2=500，每个字母表取正负样本各500个），从20个书写者中取12个。Omniglot数据集默认不是用于作匹配的，因此我们生成了自己的带标记样本。最基本的过程包括：针对一个字母表，挑选两个字符类别和两个书写人。然后组合图像形成一个匹配对和一个不匹配对。每个字母表的训练样本数固定且统一。通过添加仿射失真为每个训练样本添加8个转换，因此最终得到的相应数据集有270000个、810000个和1350000个有效样本。

为了在训练期间监控性能，我们使用了两种策略。第一种，我们为匹配创建了一个验证集，用从10个字母表和4个额外书写人中提取10000个样本。我们保留了最后10个字母表和4个书写人（30+10+10=50，12+4+4=20）用于测试。

我们的另一个策略是利用相同的字母表和书写者为验证集生成一组320个one-shot识别试验，来模拟评估集的目标任务。这种one-shot验证度量和实际性能之间有一个大致的对应关系（图5.1）；我们将在第5章更详细地讨论one-shot性能。这种确定何时停止的方法至少与使用匹配任务的验证误差一样有效，因此我们使用它作为我们的主要终止标准，如前一节所述。在下表3.1中，我们列出了六个可能的训练集的最终匹配结果，其中列出的测试正确率是在最佳模型参数下报告的。这六个网络是通过使用贝叶斯超参数优化框架Whetlab最大化一次性验证精度来选择的（轮数、样本数都属于超参数）。

从表3.1可见3层网络提供了可靠的性能而没有过拟合，而大于3层的全连接网络并没有明显提高性能。

#### 学习深度卷积分层

##### 概述

前几段卷积的介绍省略。

在one-shot学习的背景中，我们要能在无需进一步训练（重复训练）的条件下处理数百甚至数千个新的类别。如果我们不将额外结构添加到模型中，就证明这些特征（模型提取的特征）非常强大，并且不依赖于训练集中的任何特定的类分布（泛化性强）。先通过学习执行图像匹配任务的深度卷积网络，我们就能获得用于分类的有效空间特征，并将这些强有力的网络层次迁移到one-shot学习中。

##### 模型定义

省略，直接看图理解。

##### 学习

我们的学习过程与上一节描述的训练全连接孪生网络的过程相同，只做了一些小的修改。我们的卷积网络的主要区别之一是，我们使用了固定权重的初始化方案，而不考虑网络每层的单元数量。我们用均值为0、标准差为0.02正态分布初始化卷积层中的所有网络权重。偏置也由正态分布初始化，但均值为0.5，标准差为0.02。在全连接层中，偏置以与卷积层相同的方式初始化，但是权重从均值为0和标准差为0.2的更宽的正态分布中提取。

对于更大的网络，我们将训练时间限制在200轮而非300轮，因为卷积网络的训练时间可能要长得多。

##### 实验结果

为了适应我们的卷积孪生网络，我们使用了第3章中描述的相同的训练、验证和测试相分离。表4.1比较了6层卷积网络的数据。遵循常规孪生神经网络方法，我们使用Whetlab模型选择合适的超参数，如学习率、动量以及卷积滤波器的数量和大小。

我们已经从验证任务中两个表现最好的网络中提取了前32个过滤器，这两个过滤器是在具有仿射失真的90k和150k数据集上训练的。

我们还创建了可视化，将训练集和测试集映射到低维特征空间，在其中我们计算距离并利用网络进行预测。